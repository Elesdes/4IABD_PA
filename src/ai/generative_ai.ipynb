{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"../../\"\n",
    "MONITORING = os.path.join(BASE_PATH, \"logs\")\n",
    "DATA = os.path.join(BASE_PATH, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(MONITORING, \"checkpoints\")\n",
    "CNN_CHECKPOINT_PATH = os.path.join(CHECKPOINT_PATH, \"cnn\")\n",
    "RNN_CHECKPOINT_PATH = os.path.join(CHECKPOINT_PATH, \"rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TENSORBOARD_LOG_DIR = os.path.join(MONITORING, \"tensorboard_logs\")\n",
    "CNN_TENSORBOARD_LOGS = os.path.join(TENSORBOARD_LOG_DIR, \"cnn\")\n",
    "RNN_TENSORBOARD_LOGS = os.path.join(TENSORBOARD_LOG_DIR, \"rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_LOG_DIR = os.path.join(MONITORING, \"csv_logs\")\n",
    "CNN_CSV_LOGS = os.path.join(CSV_LOG_DIR, \"cnn\")\n",
    "RNN_CSV_LOGS = os.path.join(CSV_LOG_DIR, \"rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TUNERS = os.path.join(DATA, \"tuners\")\n",
    "MODELS = os.path.join(DATA, \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**GPU/TPU Multithreading Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if tpu:\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(\n",
    "        tpu,\n",
    "    )\n",
    "    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n",
    "elif len(gpus) > 1:\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy([gpu.name for gpu in gpus])\n",
    "    print(\"Running on multiple GPUs \", [gpu.name for gpu in gpus])\n",
    "elif len(gpus) == 1:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"Running on single GPU \", gpus[0].name)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"Running on CPU\")\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  # Big batch size, small learning rate\n",
    "HEIGHT, WIDTH = 224, 224\n",
    "IMG_SIZE = (HEIGHT, WIDTH)\n",
    "IMG_FORMAT = (HEIGHT, WIDTH, 3)\n",
    "NOISE_DIM = 100\n",
    "EPOCHS = 100\n",
    "SEED = 949953915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/dataset/img/mfcc\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Dataset Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=autotune)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    normalized_ds = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "    image_batch, labels_batch = next(iter(normalized_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Generator Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    noise = tf.keras.Input(shape=(NOISE_DIM,))\n",
    "    label = tf.keras.Input(shape=(1,))\n",
    "\n",
    "    label_cast = tf.cast(label, tf.int32)\n",
    "    label_one_hot = tf.one_hot(label_cast, num_classes)\n",
    "    label_reshaped = tf.keras.layers.Reshape((-1, num_classes))(label_one_hot)\n",
    "\n",
    "    noise_expanded = tf.keras.layers.Reshape((1, NOISE_DIM))(noise)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=2)([noise_expanded, label_reshaped])\n",
    "    x = tf.keras.layers.Dense((8 ** 2) * 128, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Reshape((8, 8, 128))(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    return tf.keras.Model([noise, label], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Discriminator Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    image = tf.keras.Input(shape=IMG_FORMAT)\n",
    "    label = tf.keras.Input(shape=(1,))\n",
    "\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label_one_hot = tf.one_hot(label, num_classes)\n",
    "    label_one_hot = tf.keras.layers.Reshape((-1, num_classes))(label_one_hot)\n",
    "\n",
    "    label_b = tf.keras.layers.Reshape((1, 1, num_classes))(label_one_hot)\n",
    "    label_b = tf.keras.layers.Dense(HEIGHT * WIDTH * 3, use_bias=False)(label_b)\n",
    "    label_b = tf.keras.layers.Reshape(IMG_FORMAT)(label_b)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([image, label_b])\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "    return tf.keras.Model([image, label], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Loss Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "    assert len(labels) == len(images), \"Mismatch in batch size and number of labels.\"\n",
    "\n",
    "    noise = tf.random.normal([len(images), NOISE_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator([noise, labels], training=True)\n",
    "\n",
    "        real_output = discriminator([images, labels], training=True)\n",
    "        fake_output = discriminator([generated_images, labels], training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    train_loss(disc_loss)\n",
    "    train_accuracy(tf.ones_like(real_output), real_output)\n",
    "    train_accuracy(tf.zeros_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_step(images, labels):\n",
    "    assert len(labels) == len(images), \"Mismatch in batch size and number of labels.\"\n",
    "\n",
    "    noise = tf.random.normal([len(images), NOISE_DIM])\n",
    "    generated_images = generator([noise, labels], training=False)\n",
    "\n",
    "    real_output = discriminator([images, labels], training=False)\n",
    "    fake_output = discriminator([generated_images, labels], training=False)\n",
    "\n",
    "    t_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    val_loss(t_loss)\n",
    "    val_accuracy(tf.ones_like(real_output), real_output)\n",
    "    val_accuracy(tf.zeros_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_gan():\n",
    "    with strategy.scope():\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        val_loss.reset_states()\n",
    "        val_accuracy.reset_states()\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            for train_images, train_labels in tqdm(train_dataset, desc=\"Training\"):\n",
    "                train_step(train_images, train_labels)\n",
    "\n",
    "            for test_images, test_labels in tqdm(val_dataset, desc=\"Validating\"):\n",
    "                test_step(test_images, test_labels)\n",
    "\n",
    "            template = f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {train_loss.result()}, Accuracy: {train_accuracy.result() * 100}, Val Loss: {val_loss.result()}, Val Accuracy: {val_accuracy.result() * 100}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator.save(\"generator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Generate Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = tf.keras.models.load_model('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, NOISE_DIM])\n",
    "labels = tf.constant([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_mfcc = generator([noise, labels], training=False)\n",
    "generated_mfcc = (generated_mfcc + 1) / 2.0\n",
    "generated_mfcc = tf.image.resize(generated_mfcc, [3600, 2400])\n",
    "generated_mfcc = tf.reduce_mean(generated_mfcc, axis=-1)\n",
    "generated_mfcc = tf.squeeze(generated_mfcc, axis=0)\n",
    "generated_mfcc = generated_mfcc.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(generated_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Convert Spectrogram Into Audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mel_spectrogram = librosa.feature.inverse.mfcc_to_mel(generated_mfcc)\n",
    "stft_spectrogram = librosa.feature.inverse.mel_to_stft(mel_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audio = librosa.griffinlim(stft_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf.write('reconstructed.wav', audio, 44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
